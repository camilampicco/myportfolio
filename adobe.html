<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Camila María Picco — PRMs Research Program</title>
    <meta name="description" content="Case study: PRMs Research Program with Adobe. UX research, usability testing, and insights for partner relationship management." />
    
    <!-- Open Graph / Social Sharing -->
    <meta property="og:title" content="Camila María Picco — PRMs Research Program" />
    <meta property="og:description" content="UX Research • Partner Management • Usability Testing • Insights • Collaboration" />
    <meta property="og:type" content="website" />
    
    <!-- Theme Color -->
    <meta name="theme-color" content="#0f766e" />
    
    <!-- Fonts & Styles -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="style.css">
    
    <!-- Smooth Scroll Script -->
    <script>
      document.addEventListener('DOMContentLoaded', () => {
        // Smooth scroll for anchor links
        document.querySelectorAll('a[href^="#"]').forEach(a => {
          a.addEventListener('click', e => {
            const id = a.getAttribute('href');
            if (id.length > 1) {
              e.preventDefault();
              const target = document.querySelector(id);
              if(target) {
                target.scrollIntoView({ behavior: 'smooth', block: 'start' });
              }
            }
          });
        });
      });
    </script>
  </head>
  
    <body>
        <header>
            <div class="container">
              <nav aria-label="Primary">
                <!-- Brand -->
                <div class="brand">
                  <span class="dot" aria-hidden="true"></span>
                  <a href="index.html" class="home-link"><strong>Camila María Picco</strong></a>
                </div>
                <!-- Menu (top-right buttons) -->
                <div class="links" aria-label="Sections">
                  <a class="button" href="#overview">Overview</a>
                  <a class="button" href="#process">Process</a>
                  <a class="button" href="#outcomes">Outcomes</a>
                </div>
              </nav>
            </div>
          </header>
        <main class="container">
      
          <!-- Hero Section -->
          <section class="hero fade-in">
            <h1>From Zero to Insights: PRMs Research Program</h1>
            <p class="subtitle">Transforming partner relationship management through evidence-based research and actionable insights.</p>
          </section>
      
          <!-- Overview -->
          <section id="overview" class="card fade-in two-columns">
            <div>
              <h2>Overview</h2>
              <p>The PRM  Program was designed to uncover key insights into how partners interact with Adobe products, 
                identify pain points, and inform product decisions that drive engagement and satisfaction. <br>
                <br>
                This program was designed for Adobe to enable their clients to share marketing assets with their own customers, 
                provide visibility into deals and their status, and simplify the communication of updates and news, particularly 
                during campaign heavy months such as Christmas and New Year.</p>
              <div class="kpis" role="list" aria-label="Key highlights">
                <div class="kpi" role="listitem">Qualitative user interviews</div>
                <div class="kpi" role="listitem">Usability testing rounds</div>
                <div class="kpi" role="listitem">Quantitative data</div>
                <div class="kpi" role="listitem">Implementation & Iteration</div>
              </div>
            </div>
            <div>
              <img src="images/overview-diagram.png" alt="PRMs Research Overview">
            </div>
          </section>
      
          <!-- My Role -->
          <section class="card fade-in two-columns">
            <div>
              <h2>My Role</h2>
              <p>I led the end-to-end research process, from scoping objectives to recruiting participants, 
                executing interviews and usability testing, and synthesising findings into actionable recommendations. <br>
                <br>
                My primary responsibility was to act as a communication bridge between the PRM provider and Adobe. 
                On one hand, I collaborated with the PRM vendor using technical terminology and by reviewing the backend code of the system. 
                On the other hand, I worked directly with Adobe to understand their user-facing needs, 
                clarifying what could or could not be achieved within the PRM's capabilities.
                <br>
                <br>
                Once we aligned on goals and defined what was feasible, I recruited participants and test the program.</p>
              <div class="pills-container">
                <span class="pill">User Interviews</span>
                <span class="pill">Usability Testing</span>
                <span class="pill">Synthesis & Analysis</span>
                <span class="pill">Stakeholder Collaboration</span>
              </div>
            </div>
            <div>
              <img src="images/my-role.png" alt="My Role in Research">
            </div>
          </section>

        <!-- Usability Testing Process -->
            <section  id="process" class="card fade-in">
                <div class="process-images">
                    <h2>Usability Testing Process</h2>
                    <h3>Overview</h3>
                    <p>For this usability test, we conducted two cycles. We began by recruiting five participants for the first cycle
                        and defining the structure of the sessions. <br><br>
                        The tests were conducted remotely, moderated by me, with an observer taking detailed notes. <br>
                        We established success criteria and post-test questions, and we also included the use of the NPS score 
                        to gather responses upon completion of each session. <br><br>
                        A participation agreement was drafted and shared with all participants prior to the test, ensuring informed consent. <br>
                        Additionally, we ran an internal pilot test to refine the process before launching the study.
                    </p>
                    <img src="assets/overview_usabilitytest.PNG" alt="Overview usability test" class="large-img"> <br>
                
                    <h3>Success Criteria</h3>
                    <p>For the usability test, we designed a set of twelve tasks to comprehensively evaluate the PRM. <br>
                    The tasks were carefully selected to cover areas frequently discussed among stakeholders, ensuring that
                    their main concerns were directly assessed. <br> <br> In addition, I incorporated potential pain points that
                    had not yet been raised but were likely to affect the user experience. <br>
                    </p>
                    <img src="assets/successcriteria_usability.PNG" alt="Success criteria usability" class="large-img"> <br>
                
                    <h3>Tasks</h3>
                    <p>The list of tasks participants had to complete during the test.</p>
                    <img src="assets/tasks_usability.PNG" alt="Tasks usability" class="large-img"> <br>
                
                    <h3>Partner Scoring</h3>
                    <p>The rating scale was developed for each task and for each individual participant, based on the defined success criteria. <br>
                     In this context, the ratings are as follows: <br>
                    Complete Success = 3, Partial Success = 2, Success with Failure = 1, and Failure = 0.</p>
                    <img src="assets/partnerscoring_usability.PNG" alt="Partner scoring usability" class="large-img"> <br>
                
                    <h3>Participants Comments</h3>
                    <p>Participant comments were carefully considered, ranging from body language and posture to verbal cues such as expressions like 'I guess' or 'I reckon' versus more confident statements like 'I am sure that.' Additionally, we recorded the time each participant took to complete each task, providing further insight into task difficulty and user performance.</p>
                    <img src="assets/comments_usability.PNG" alt="Comments usability" class="large-img"> <br>
                
                    <h3>Results</h3>
                    <p>Based on the task scores mentioned previously, an average score was calculated for each task. 
                        This average was then used to measure Effectiveness (Level of Success), with 0 representing Failure and 3 representing 
                        Complete Success. <br> 
                        <br>Next, the average time taken per task was calculated (Time on Task) to further assess Effectiveness. 
                        In addition, a problem log was created, taking into account all the issues and observations mentioned by the participants.</p>
                    <img src="assets/results_usability.PNG" alt="Results usability" class="large-img"> <br>
                
                    <h3>Conclusions</h3>
                    <p>For the conclusions, I created a presentation designed in Figma. One section detailed each task, including its 
                        description, the average completion time, the completion rate, and the number of participants who required assistance. Specific participant comments related to each task were also included. <br>
                        <br>Additionally, the presentation featured an executive summary and a separate section with recommendations.</p>
                    <img src="assets/usability_slides.png" alt="Usability slides" class="large-img">  <br>
                    <img src="assets/executive_summary.png" alt="Executive summary" class="large-img">    <br>
                
                    <h3>Likert Scale Evaluation</h3>
                    <p>
                    In addition to interviews and usability testing, I designed and ran a short 
                    Likert scale survey to capture quantitative insights. Participants were asked:
                    </p>
                    <ul>
                        <li><em>“How satisfied are you with the PRP?”</em></li>
                        <li><em>“Why did you give this score?”</em></li>
                    </ul>
                    <p>
                    This allowed us to measure perceived satisfaction, identify gaps between 
                    expectations and experience, and validate qualitative findings with numerical trends.
                    </p>
                </div>
            </section>   
      
          <!-- Outcomes -->
           
          <section id="outcomes" class="card fade-in two-columns">
            <div>
              <h2>Outcomes & Impact</h2>
              <p>The usability test was conducted in two cycles, with a second round of five participants after implementing improvements. The outcomes demonstrate significant gains in completion rates, efficiency, and overall platform engagement.</p>
          
              <h3>Completion Rate Improvements</h3>
              <ul>
                <li>Task 3: 16.7% → 80%+</li>
                <li>Task 4: 40% → 75%+</li>
                <li>Task 7: 40% → 75%+</li>
                <li>Task 1: +10% increase</li>
                <li>Task 2: +10% increase</li>
              </ul>
          
              <h3>Participant Confidence & Behavior</h3>
              <ul>
                <li>Noticeable reduction in hesitation during responses in Cycle 2.</li>
                <li>More confident statements such as “I am sure that…” observed across tasks.</li>
              </ul>
          
              <h3>Time on Task</h3>
              <ul>
                <li>Task 7: reduced by more than 10 seconds</li>
                <li>Task 8: reduced by more than 10 seconds</li>
                <li>Other tasks remained similar to Cycle 1 values</li>
              </ul>
          
              <h3>Platform Engagement & Conversions</h3>
              <ul>
                <li>Higher partner traffic observed on the platform after improvements.</li>
                <li>Conversion rates increased, indicating better overall user experience.</li>
              </ul>
          
              <h3>Key Insights</h3>
              <ul>
                <li>Iterative testing and design changes significantly improved task completion and efficiency.</li>
                <li>Higher confidence and reduced hesitation indicate clearer UI and better guidance.</li>
                <li>Business metrics such as platform traffic and conversions show positive impact beyond usability metrics.</li>
              </ul>
            </div>
          </section>
             
        </main>
      </body>
      </html>